<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1000px;
	}
	h1 {
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 0px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>Toward Multimodal Image-to-Image Translation</title>
		<meta property="og:image" content="https://junyanz.github.io/BicycleGAN/index_files/teaser_fb2.jpg" />
		<meta property="og:title" content="Toward Multimodal Image-to-Image Translation. In NIPS, 2017." />
  </head>

  <body>
    <br>
          <center>
          	<span style="font-size:42px">Toward Multimodal Image-to-Image Translation</span><br>
	  		  <table align=center width=1000px>
	  		  <!-- <table align=center width=540px> -->
	  			  <tr>
	  	              <td align=center width=200px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://www.cs.cmu.edu/~junyanz/">Jun-Yan Zhu</a></span><sup>1</sup>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=200px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://richzhang.github.io/">Richard Zhang</a></span><sup>1</sup>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=200px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://people.eecs.berkeley.edu/~pathak/">Deepak Pathak</a></span><sup>1</sup>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=200px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell</a></span><sup>1</sup>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=200px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></span><sup>1</sup>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=200px>
	  					<center>
	  						<span style="font-size:18px"><a href="http://www.oliverwang.info/">Oliver Wang</a></span><sup>2</sup>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=200px>
	  					<center>
	  						<span style="font-size:18px"><a href="https://research.adobe.com/person/eli-shechtman/">Eli Shechtman</a></span><sup>2</sup>
		  		  		</center>
		  		  	  </td>
	  			  </tr>
			  </table>
	  		  <table align=center width=1000px>
	  			  <tr>
	  	              <td align=center width=100px>
	  					<center>
				          	<span style="font-size:18px"></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=200px>
	  					<center>
				          	<span style="font-size:18px"><sup>1</sup>Berkeley Artificial Intelligence Research</span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=200px>
	  					<center>
				          	<span style="font-size:18px"><sup>2</sup>Adobe Creative Intelligence Laboratory</span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
				          	<span style="font-size:18px"></span>
		  		  		</center>
		  		  	  </td>
			  </table>
	  		  <table align=center width=1000px>
	  			  <tr>
	  	              <td align=center width=275px>
	  					<center>
				          	<span style="font-size:18px"></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=225px>
	  					<center>
	  						<span style="font-size:22px">Code <a href='https://github.com/junyanz/BicycleGAN'> [GitHub]</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=225px>
	  					<center>
	  						<span style="font-size:22px">NIPS 2017<a href="https://arxiv.org/abs/1711.11586"> [Paper]</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=275px>
	  					<center>
				          	<span style="font-size:18px"></span>
		  		  		</center>
		  		  	  </td>
			  </table>
          </center>

  		  <table align=center width=900px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<img class="rounded" src = "./index_files/teaser.jpg" height="300px"></img>
  	                	<br>
					</center>
  	              </td>
  	              </tr>
  	              </table>

  		  <br>
		  <hr>

  		  <table align=center width=900px>
	  		 	<center><h1>Abstract</h1></center>
	  		 	<tr>
		            <!-- <td align=center width=600px> -->
					<p align="justify">Many image-to-image translation problems are ambiguous, as a single input image
					may correspond to multiple possible outputs. In this work, we aim to model
					a <i>distribution</i> of possible outputs in a conditional generative modeling setting.
					The ambiguity of the mapping is distilled in a low-dimensional latent vector,
					which can be randomly sampled at test time. A generator learns to map the given
					input, combined with this latent code, to the output. We explicitly encourage the
					connection between output and the latent code to be invertible. This helps prevent
					a many-to-one mapping from the latent code to the output during training, also
					known as the problem of mode collapse, and produces more diverse results. We
					explore several variants of this approach by employing different training objectives,
					network architectures, and methods of injecting the latent code. Our proposed
					method encourages bijective consistency between the latent encoding and output
					modes. We present a systematic comparison of our method and other variants on
					both perceptual realism and diversity.</p>
					<!-- </td> -->
				</tr>
  		  <br>
		  <hr>

  		  <table align=center width=900px>
	  		 	<center><h1>Demo Video</h1></center>
  			  <tr>
<!--   	              <td width=400px>
  					<center>
  	                	<img class="rounded" src = "./index_files/teaser_v3.jpg" height="275px"></img>
  	                	<br>
					</center>
  	              </td> -->
		  		  <table align=center width=600px>
		  		    <tr>
		              <td align=center width=600px>
						<iframe width="800" height="450" src="https://www.youtube.com/embed/JvGysD2EFhw" frameborder="0" allowfullscreen></iframe>
					  </td>
					</tr>
				  </table>
				<br>
                </tr>
  		  </table>

        <center><a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN//video_extended.mp4">mp4</a> [258 MB]</center>
  		  <br>

		  <hr>

 		<center><h1>Example Results</h1></center>

  		  <table align=center width=600px>
  		    <tr>
              <td align=center width=600px>
        		<!-- <a href="./index_files/legacy_v4.jpg"><img class="rounded"  src = "./index_files/legacy_v4_small.jpg" width = "800px"></a><br> -->
        		<a href=""><img class="rounded"  src = "./index_files/results_matrix.jpg" width = "800px"></a><br>
				<span style="font-size:16px"></span>
			  </td>
			</tr>
		  </table>
  		  <table align=center width=800px>
  		  	<tr>
		        <td align=center width=800px>
					<span style="font-size:16px"><b>Unsynchronized z</b>
					<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN//web_arxiv/facades_random_z_20_20/">[labels &rarr; facades]</a>
					<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN//web_arxiv/shoes_random_z_20_20/">[edges &rarr; shoes]</a>
					<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN//web_arxiv/handbags_random_z_20_20/">[edges &rarr; handbags]</a>
					<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN//web_arxiv/night2day_random_z/">[night &rarr; day]</a>
					</span>
				</td>
			</tr>
  		  	<tr>
		        <td align=center width=800px>
					<span style="font-size:16px"><b>Synchronized z</b>
					<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN//web_arxiv/facades_fixed_z_100_6/">[labels &rarr; facades]</a>
					<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN//web_arxiv/shoes_fixed_z_50_6/">[edges &rarr; shoes]</a>
					<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN//web_arxiv/handbags_fixed_z_100_6/">[edges &rarr; handbags]</a>
					<a href="http://efrosgans.eecs.berkeley.edu/BicycleGAN//web_arxiv/night2day_random_z/">[night &rarr; day]</a>
					</span>
				</td>
			</tr>
		</table>

		<hr>

		<center><h1> Exploring the Latent Space</h1><center>
		<table align=center width=800px>
			<tr>
				<td align=center>
					<a href="./index_files/day2night.gif"><img src = "./index_files/day2night.gif"></a><br>
					<span style="font-size:16px"></span>
				</td>
			</tr>
		</table>

		<hr>

 		<center><h1>Try the BicycleGAN model</h1></center>

  		  <table align=center width=900px>
  			  <tr>
  	                <td align=center width=900px>
  					<center>
						  <td><a href='https://github.com/junyanz/BicycleGAN'><img class="round" style="width:900px" src="./index_files/network2.jpg"/></a></td>
	  		  		</center>
	  		  		</td>
			  </tr>
		  </table>

		  <br>

  		  <table align=center width=800px>
			  <tr><center>
				<span style="font-size:28px"><a href='https://github.com/junyanz/BicycleGAN'>[GitHub]</a>
			  <br>
			  </center></tr>
		  </table>
		  <br>

		  <hr>

  		  <table align=center width=600 px>
	 		<center><h1>Paper</h1></center>
  			  <tr>
				  <td><a href="https://arxiv.org/abs/1711.11586"><img class="layered-paper-big" style="height:175px" src="./index_files/page1.jpg"/></a></td>
				  <td><span style="font-size:12pt">J.Y. Zhu, R. Zhang, D. Pathak, <br> T. Darrell, A. A. Efros, O. Wang, E. Shechtman.</span><br>
				  <b><span style="font-size:12pt">Toward Multimodal Image-to-Image Translation.</b></span><br>
				  <span style="font-size:12pt">In NIPS, 2017. (hosted on <a href="https://arxiv.org/abs/1711.11586">arXiv</a>)</span></a>
				  <span style="font-size:4pt"><a href=""><br></a>
				  </span>
				  </td>
  	              </td>
              </tr>
  		  </table>
		  <br>

		  <table align=center width=600px>
			  <tr>
				  <td><span style="font-size:24pt"><center>
				  	<a href="./index_files/bibtex_nips2017.txt">[Bibtex]</a>
  	              </center></td>
              </tr>
  		  </table>

  		  <br>
		  <hr>

  		  <table align=center width=200 px>
	 		<center><h1>Poster</h1></center>
  			  <tr>
				  <td><a href="./index_files/poster_nips_v3.pdf"><img class="paper-big" style="width:600px" src="./index_files/poster_teaser.png"/></a></td>
              </tr>
  		  </table>
		  <br>

		  <table align=center width=600px>
			  <tr>
				  <td><span style="font-size:24pt"><center>
				  	<a href="./index_files/poster_nips_v3.pdf">[PDF]</a>
  	              </center></td>
              </tr>
  		  </table>

  		  <br>
		  <hr>

  		  <table align=center width=1000px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		  <center><h1>Related Work</h1></center>
					Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei. A. Efros. <b>Image-to-image translation with conditional adversarial networks.</b> In CVPR, 2017. <a href="https://arxiv.org/pdf/1611.07004v1.pdf">[PDF]</a><a href="https://phillipi.github.io/pix2pix/"> [Website]</a></br>

					<br>

					Jun-Yan Zhu*, Taesung Park*, Phillip Isola, Alexei A. Efros. <b>Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.</b> In ICCV, 2017. <a href="https://arxiv.org/abs/1703.10593"> [PDF]</a><a href="https://junyanz.github.io/CycleGAN/"> [Website]</a></br>

					<br>

			</left>
		</td>
			 </tr>
		</table>
		<hr>

  		  <table align=center width=1000px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
				<p align="justify">We thank Phillip Isola and Tinghui Zhou for helpful discussions. This work wassupported in part by Adobe Inc., DARPA, AFRL, DoD MURI award N000141110688, NSF awards IIS-1633310, IIS-1427425, IIS-1212798, the Berkeley Artificial Intelligence Research (BAIR) Lab,and hardware donations from NVIDIA. JYZ is supported by the Facebook Graduate Fellowship, RZ by the Adobe Research Fellowship, and DP by the NVIDIA Graduate Fellowship.</p>
			</left>
		</td>
			 </tr>
		</table>

		<br><br>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75863369-4', 'auto');
  ga('send', 'pageview');

</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-75863369-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-75863369-4');
</script> -->


</body>
</html>
